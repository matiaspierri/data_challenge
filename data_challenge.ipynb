{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aeTxp_jutv9q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkHWL1eRtxj5"
   },
   "source": [
    "## Install dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v9jzAHyotzyx",
    "outputId": "2995399d-3828-4eb4-b1fa-4837ff1087fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: memory-profiler in /Users/matiaspierri/anaconda3/lib/python3.11/site-packages (0.61.0)\r\n",
      "Requirement already satisfied: emoji in /Users/matiaspierri/anaconda3/lib/python3.11/site-packages (2.8.0)\r\n",
      "Requirement already satisfied: psutil in /Users/matiaspierri/anaconda3/lib/python3.11/site-packages (from memory-profiler) (5.9.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install memory-profiler emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "I4jOjhzRt7ch"
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import json\n",
    "import cProfile\n",
    "import emoji\n",
    "import datetime\n",
    "from memory_profiler import profile\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QZYPxq_QuBOk"
   },
   "outputs": [],
   "source": [
    "# Auxiliary function to load JSON into Dataframe\n",
    "def load_JSON_into_df(file_path: str):\n",
    "\n",
    "    data= []\n",
    "    invalid_rows= []\n",
    "\n",
    "    missing_rows = 0\n",
    "\n",
    "    # Try to read the JSON file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        # Read and parse each line separately\n",
    "        for row in file:\n",
    "            try:\n",
    "                jsonparse = json.loads(row)\n",
    "                data.append(jsonparse)\n",
    "            except Exception as e:\n",
    "                missing_rows +=1\n",
    "                invalid_rows.append(row)\n",
    "\n",
    "    print(f'Missing rows: {missing_rows}')\n",
    "    print(f'Invalid rows: {invalid_rows}')\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8TjTuWQruIQr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pzC1EnSDvT1R"
   },
   "source": [
    "## Data Challenge resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-SRldIuvW4E"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oho5UN5SvYVr"
   },
   "source": [
    "### Question 1\n",
    "\n",
    "The top 10 dates with the most tweets. Mention the user (username) with the most posts for each of those days. This script returns the following data type: List[Tuple[datetime.date, str]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KlOB438YvXo7"
   },
   "outputs": [],
   "source": [
    "@profile\n",
    "def find_top_10_tweets_count_dates(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "\n",
    "    # Create a DataFrame from the parsed data\n",
    "    df = load_JSON_into_df(file_path)\n",
    "\n",
    "\n",
    "    # Removing hours, minutes and seconds\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.strftime('%m-%d-%Y')\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "\n",
    "    # Extracting username information\n",
    "    df['username'] = df['user'].apply(lambda x: x['username'])\n",
    "\n",
    "    # Counting tweets aggregated by date + username\n",
    "    top_users = df.groupby('date')['username'].value_counts().reset_index(name='record_count')\n",
    "\n",
    "    # Sort the DataFrame by 'record_count' in descending order\n",
    "    top_users = top_users.sort_values(by=['date', 'record_count'], ascending=[True, False])\n",
    "\n",
    "    # Top 10 dates and username with most tweets by that given date\n",
    "    top10_users = top_users.groupby('date').max().reset_index().head(10)\n",
    "\n",
    "\n",
    "    # Returning result in a tuple\n",
    "    return [tuple(row[['date', 'username']]) for _, row in top10_users.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tvTxoJqYvTT2",
    "outputId": "e603d570-a720-4919-b3f4-b0a2a5a6ab09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find file /var/folders/35/x4p_8f_n1t7cw1_k8r37b8700000gn/T/ipykernel_43834/3189519986.py\n",
      "Missing rows: 0\n",
      "Invalid rows: []\n",
      "[(datetime.date(2021, 2, 12), 'zsheikh_INC'), (datetime.date(2021, 2, 13), 'zundar'), (datetime.date(2021, 2, 14), 'zlz_raa'), (datetime.date(2021, 2, 15), 'zuberjafri'), (datetime.date(2021, 2, 16), 'zlz_raa'), (datetime.date(2021, 2, 17), 'zlz_raa'), (datetime.date(2021, 2, 18), 'zlz_raa'), (datetime.date(2021, 2, 19), 'zia_khan2k'), (datetime.date(2021, 2, 20), 'zlz_raa'), (datetime.date(2021, 2, 21), 'zoo_bear')]\n"
     ]
    }
   ],
   "source": [
    "top_10_dates = find_top_10_tweets_count_dates(\"farmers-protest-tweets-2021-2-4.json\")\n",
    "print(top_10_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "The top 10 most used emojis with their respective counts. This script returns the following data type: List[Tuple[str, int]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract emojis from a string using the emoji module\n",
    "def extract_emojis(text):\n",
    "    return ''.join(char for char in text if emoji.is_emoji(char))\n",
    "\n",
    "\n",
    "@profile\n",
    "def find_top_10_emojis_count(file_path: str) -> List[Tuple[str, int]]:\n",
    "\n",
    "    # Create a DataFrame from the parsed data\n",
    "    df = load_JSON_into_df(file_path)\n",
    "\n",
    "    # Apply the extract_emojis function to the \"content\" column\n",
    "    df['emojis'] = df['content'].apply(extract_emojis)\n",
    "\n",
    "    # Transforming all emojis coming from tweets in just one line\n",
    "    emojis_extracted = df['emojis'].str.cat()\n",
    "\n",
    "    # Dict to save emoji + count\n",
    "    emj_count = {}\n",
    "\n",
    "    # Iterate through the emojis\n",
    "    for emj in emojis_extracted:\n",
    "        \n",
    "        # If emoji is not in the dictionary, add it with a count of 1\n",
    "        if emj not in emj_count:\n",
    "            emj_count[emj] = 1\n",
    "        # If the emoji is already in the dictionary, increment its count\n",
    "        else:\n",
    "            emj_count[emj] += 1\n",
    "\n",
    "    # Convert the dictionary to a list of tuples (emoji, count)\n",
    "    emj_count_tuple = [(emj, count) for emj, count in emj_count.items()]\n",
    "\n",
    "    # Sort the list of tuples by count in descending order\n",
    "    sorted_tuples = sorted(emj_count_tuple, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Return the sorted list of tuples as a tuple. Only keeping the top 10\n",
    "    return tuple(sorted_tuples[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find file /var/folders/35/x4p_8f_n1t7cw1_k8r37b8700000gn/T/ipykernel_43834/3926645500.py\n",
      "Missing rows: 0\n",
      "Invalid rows: []\n",
      "(('ðŸ™', 7286), ('ðŸ˜‚', 3072), ('ðŸšœ', 2972), ('âœŠ', 2411), ('ðŸŒ¾', 2363), ('ðŸ»', 2080), ('â¤', 1779), ('ðŸ¤£', 1668), ('ðŸ½', 1218), ('ðŸ‘‡', 1108))\n"
     ]
    }
   ],
   "source": [
    "top_10_emojis = find_top_10_emojis_count(\"farmers-protest-tweets-2021-2-4.json\")\n",
    "print(top_10_emojis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "top_10_most_mentioned_users: The historical top 10 most influential users (username) based on the count of mentions (@) each of them registers. This script returns the following data type: List[Tuple[str, int]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_10_most_mentioned_users(file_path: str) -> List[Tuple[str, int]]:\n",
    "\n",
    "    # Create a DataFrame from the parsed data\n",
    "    df = load_JSON_into_df(file_path)\n",
    "\n",
    "    # Drop rows with None or NaN values in the \"mentionedUsers\" column\n",
    "    # We only want to keep users that were mentioned\n",
    "    df.dropna(subset=['mentionedUsers'], inplace=True)\n",
    "\n",
    "    df['usernameMentionedList'] = df['mentionedUsers'].apply(lambda user_list: [user['username'] for user in user_list if 'username' in user])\n",
    "\n",
    "    username_mentioned_plain_string = ' '.join(' '.join(username_list) for username_list in df['usernameMentionedList'])\n",
    "\n",
    "    # Create a dictionary that contains the count of each username\n",
    "    username_mention_count = {}\n",
    "\n",
    "    for username in username_mentioned_plain_string.split():\n",
    "        if username in username_mention_count:\n",
    "            username_mention_count[username] += 1\n",
    "        else:\n",
    "            username_mention_count[username] = 1\n",
    "\n",
    "    # Transform the dictionary into a list of tuples, ordered by descending count\n",
    "    sorted_username_tuples = sorted(username_mention_count.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Keep only top 10\n",
    "    return tuple(sorted_username_tuples[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing rows: 0\n",
      "Invalid rows: []\n",
      "(('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926))\n"
     ]
    }
   ],
   "source": [
    "top_10_mentioned_users = find_top_10_most_mentioned_users(\"farmers-protest-tweets-2021-2-4.json\")\n",
    "print(top_10_mentioned_users)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
